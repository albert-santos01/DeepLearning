{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"EvWs2XIYNfhg"},"source":["# **SVHN Dataset**\n","In the following exercices, you will work with the SVHN dataset: http://ufldl.stanford.edu/housenumbers/\n","\n","It contains RGB images of street digits labeled from 1 to 10 similar to the MNIST dataset.\n","\n","The train and test sets are provided in the folder Data/svhn/ in .mat format.\n","In the following we show an example of how to load the images and labels from these files. A DataLoader for this dataset is provided in the code examples for the lab."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4JNFtVgFNaN3"},"outputs":[{"name":"stdout","output_type":"stream","text":["labels:  (73257,) images:  (32, 32, 3, 73257)\n","Label: 9\n"]},{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x232b693e590>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Basic example loading images from the svhn dataset\n","import scipy.io as sio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","\n","try: \n","    base_path\n","except NameError:\n","    base_path = os.getcwd().replace('\\\\','/')\n","data_path = base_path + '/Data/'\n","results_path = base_path + '/Results/'\n","\n","# Load mat file with train images from SVHN\n","import scipy.io as sio\n","train_mat = sio.loadmat(data_path + 'svhn/train_32x32.mat')\n","\n","images = train_mat['X']\n","labels = train_mat['y'].squeeze()\n","\n","example_image, example_label = images[:,:,:,6], labels[6] \n","print(\"labels: \", labels.shape, \"images: \", images.shape)\n","print('Label: ' + str(example_label))\n","plt.imshow(example_image)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zDulabPxYZXi"},"source":["# Ex. 1\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-NwccV9Wzl39"},"source":["'''\n","1. Try to obtain the maximum test accuracy possible in the SVHN dataset. For this purpose train/test different variants of the CNN provided in P3-Part1-Examples.\n","   You can explore different strategies:\n","1.1. Increase the size of the network by adding one ore more conv. layers. You can also increase the number of filters in each layer.\n","1.2. Try different optimizers such as Adam or SGD with momentum and modify the learning rate. You can check: https://pytorch.org/docs/stable/optim.html\n","1.3. Explore different random transformations during training ( Data augmentation ) such as random cropping with padding. \n","You can check: https://pytorch.org/docs/stable/torchvision/transforms.html . Remember that these random transofrmation must not be used during testing.\n","1.4 Whatever you consider...\n","\n","\n","2. Save all the different models , compare their test accuracy and analyse the results. Discuss what model has been shown more effective and why have you used the different strategies.\n","'''"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TA0aJf5Szxdv"},"source":["# Sol. 1"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#Making native class loader\n","import PIL.Image as Image\n","\n","class SVHN(torch.utils.data.Dataset):\n","    # Initialization method for the dataset\n","    def __init__(self,dataDir = data_path+'/svhn/train_32x32.mat',transform = None):\n","        mat_loaded = sio.loadmat(dataDir)\n","        self.data = mat_loaded['X']\n","        self.labels = mat_loaded['y'].squeeze()\n","        self.labels -= self.labels.min()\n","        self.transform = transform\n","     # What to do to load a single item in the dataset ( read image and label)    \n","    def __getitem__(self, index):\n","        data = self.data[:,:,:,index]\n","        lbl = self.labels[index]\n","        \n","        data = Image.fromarray(data)\n","        # Apply a trasnformaiton to the image if it is indicated in the initalizer\n","        if self.transform is not None : \n","            data = self.transform(data)\n","        \n","        # return the image and the label\n","        return data,lbl\n","    \n","        pass\n","    \n","    # Return the number of images\n","    def __len__(self):\n","        return self.data.shape[3]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Base CNN"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Define an standard CNN -> Two conv. blocks and linear layer \n","import torch.nn as nn\n","class BaseConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(BaseConvNet, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5,  padding=2).cuda()\n","        #input : 3 channel, output 16 channel, filter size : 5x5 and padding 2\n","        # the ouput of this channel will be 16x32x32 (assuming our image is in fact 32x32) since the pixels\n","        # that the convolution operation collapses into are 32x32 (the padding is 2 so the image is not reduced)\n","        \n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3,  padding=1).cuda()\n","        #input : 16 channel, output 32 channel, filter size : 3x3\n","        # simmilary the output of this channel will be 32x32x32. If the kernel is 3x3, then the dimensions are reduced by\n","        # 2 (since the padding is 1) in both height and width, but the padding counters this.\n","        \n","        self.fc = nn.Linear(8*8*32, num_classes).cuda\n","        # must match the previous dimensions in the input. In the case of the SVHM dataset, the input is 32x32x3, and after\n","        # doing 2 convolutions that do not reduce the height and width, but 2 maxpooling operations after the convolutions, the\n","        # dimensions are 8x8x32, since the final channel number is 32. The 8*8*32 is the number of pixels in the image after the \n","        # convolutions, and the number of channels\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2).cuda()\n","        self.relu = nn.ReLU().cuda()\n","        \n","    def forward(self, x):\n","        \n","        out = self.conv1(x)\n","        out = self.relu(out)\n","        out = self.maxpool(out)\n","        \n","        out = self.conv2(out)\n","        out = self.relu(out)\n","        out = self.maxpool(out)\n","        \n","        out = out.reshape(out.size(0), -1) \n","        out = self.fc(out) # we don't need sigmoid or other activation function at the end beacuse we will use nn.CrossEntropyLoss() (check documentation to understand why)\n","        \n","        return out \n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from torch.optim import lr_scheduler as lrs"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Train function\n","def train(CNN, train_loader, optimizer, num_epochs=5, model_name='model.ckpt', device='cpu'):\n","    CNN.train() # Set the model in train mode\n","    scheduler = lrs.ExponentialLR(optimizer, gamma=0.9)\n","    total_step = len(train_loader)\n","    losses_list = []\n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        for i, (images, labels) in enumerate(train_loader):\n","            # Get batch of samples and labels\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            \n","            # Forward pass\n","            outputs = CNN(images)\n","            loss = criterion(outputs, labels)\n","            losses_list.append(loss.item())\n","            \n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if (i+1) % 100 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                        .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","        scheduler.step()\n","          \n","    return losses_list \n","\n","# Test funcion\n","def test(CNN, test_loader):\n","  with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            # get network predictions\n","            outputs = CNN(images)\n","\n","            # get predicted class\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            # compare with the ground-truth\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        # return accuracy\n","        return 100 * correct / total"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["BaseCNN = BaseConvNet()\n","# CNN = CNN.cuda()\n","import torchvision.transforms as tf\n","\n","# Create train data loader\n","tr = tf.Compose([\n","        tf.ToTensor(), \n","        tf.Normalize(mean = [.5], std = [.5])\n","        ])\n","SVHNTrain = SVHN(data_path+'/svhn/train_32x32.mat',tr)\n","train_loader = torch.utils.data.DataLoader(dataset=SVHNTrain,\n","                                               batch_size=256, \n","                                               shuffle=True)\n","\n","SVHNTest = SVHN(data_path+'/svhn/test_32x32.mat',tr)\n","test_loader = torch.utils.data.DataLoader(dataset=SVHNTest,\n","                                               batch_size=256, \n","                                               shuffle=True)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'BaseCNN' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m#Initialize optimizer \u001b[39;00m\n\u001b[0;32m      5\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m.001\u001b[39m\n\u001b[1;32m----> 6\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(BaseCNN\u001b[39m.\u001b[39mparameters(),lr \u001b[39m=\u001b[39m learning_rate)\n\u001b[0;32m      9\u001b[0m \u001b[39m# Device configuration (choose GPU if it is available )\u001b[39;00m\n\u001b[0;32m     10\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'BaseCNN' is not defined"]}],"source":["# Cross entropy loss for classification problems\n","criterion = nn.CrossEntropyLoss()\n","\n","#Initialize optimizer \n","learning_rate = .001\n","optimizer = torch.optim.Adam(BaseCNN.parameters(),lr = learning_rate)\n","\n","\n","# Device configuration (choose GPU if it is available )\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","num_epochs = 5\n","\n","# Train and test the model\n","loss_hist = train(BaseCNN, train_loader, optimizer, num_epochs, model_name='base_model.pkt', device=device)\n","plt.plot(loss_hist)\n","plt.show()\n","\n","\n","print('Test accuracy is: {} %'.format(test(BaseCNN, test_loader)))\n","# Create test data loader\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Refined CNN's"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We will not create a CNN class for each hyperparameter configuration. Instead, we will change the RefinedConvNet class"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Compute model paramters\n","def compute_model_params(model):\n","  params = 0\n","  for p in model.parameters():\n","    params+= p.numel()\n","  return params"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## More Layers LONG"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel Parameters: 87290\n"]}],"source":["# Define an standard CNN -> Two conv. blocks and linear layer \n","import torch.nn as nn\n","class LongConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(LongConvNet, self).__init__()\n","        \n","        self.conv11 = nn.Conv2d(3, 16, kernel_size=5,  padding=2).cuda() \n","        \n","    \n","        self.conv12 = nn.Conv2d(16, 16, kernel_size=5, padding=2).cuda()\n","        # after maxpooling, the dimensions are 16x16x16\n","\n","        self.conv21 = nn.Conv2d(16, 32, kernel_size=3, padding=1).cuda()\n","\n","        self.conv22 = nn.Conv2d(32, 32, kernel_size=3, padding=1).cuda()\n","        # after maxpooling, the dimensions are 8x8x32\n","\n","        self.conv31 = nn.Conv2d(32, 64, kernel_size=3, padding=1).cuda()\n","        self.conv32 = nn.Conv2d(64, 64, kernel_size=3, padding=1).cuda()\n","        # after maxpooling, the dimensions are 3x3x64\n","        \n","        self.fc = nn.Linear(4*4*64, num_classes).cuda()\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2).cuda()\n","        self.relu = nn.ReLU().cuda()\n","        # self.batchnorm = nn.BatchNorm2d(16).cuda()\n","        self.batchnorm2 = nn.BatchNorm2d(16).cuda()\n","        self.batchnorm3 = nn.BatchNorm2d(32).cuda()\n","# \n","        \n","    def forward(self, x):\n","        \n","        out11 = self.relu(self.conv11(x))\n","        out12 = self.batchnorm2(self.relu(self.conv12(out11))) + out11\n","        out = self.maxpool(out12)\n","        \n","\n","        out21 = self.relu(self.conv21(out))\n","        out22 = self.batchnorm3(self.relu(self.conv22(out21))) + out21\n","        out = self.maxpool(out22)\n","\n","        out31 = self.relu(self.conv31(out))\n","        out32 = self.relu(self.conv32(out31)) + out31\n","        out = self.maxpool(out32)\n","        \n","        \n","        out = out.reshape(out.size(0), -1) \n","        out = self.fc(out) # we don't need sigmoid or other activation function at the end beacuse we will use nn.CrossEntropyLoss() (check documentation to understand why)\n","        \n","        return out \n","\n","model = LongConvNet(num_classes=10)\n","n_params = compute_model_params(model)\n","print(\"MyModel Parameters: \" + str(n_params))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## proposed ResNet"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel Parameters: 131402\n"]}],"source":["# Define an standard CNN -> Two conv. blocks and linear layer \n","import torch.nn as nn\n","class Proposal(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(Proposal, self).__init__()\n","        \n","        self.conv11 = nn.Conv2d(3, 16, kernel_size=3,  padding=1).cuda() \n","        self.conv12 = nn.Conv2d(16, 16, kernel_size=3, padding=1).cuda()\n","        self.conv13 = nn.Conv2d(16, 16, kernel_size=3, padding=1).cuda()\n","        # after maxpooling, the dimensions are 16x16x16\n","\n","        self.conv21 = nn.Conv2d(16, 32, kernel_size=3, padding=1).cuda()\n","        self.conv22 = nn.Conv2d(32, 32, kernel_size=3, padding=1).cuda()\n","        self.conv23 = nn.Conv2d(32, 32, kernel_size=3, padding=1).cuda()\n","        # after maxpooling, the dimensions are 8x8x32\n","\n","        self.conv31 = nn.Conv2d(32, 64, kernel_size=3, padding=1).cuda()\n","        self.conv32 = nn.Conv2d(64, 64, kernel_size=3, padding=1).cuda()\n","        self.conv33 = nn.Conv2d(64, 64, kernel_size=3, padding=1).cuda()\n","        # after maxpooling, the dimensions are 4x4x64\n","        \n","        self.fc = nn.Linear(4*4*64, num_classes).cuda()\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2).cuda()\n","        self.avgpool= nn.AvgPool2d(kernel_size=2, stride=2).cuda()\n","\n","        self.relu = nn.ReLU().cuda()\n","        self.bn11 = nn.BatchNorm2d(16).cuda()\n","        self.bn12 = nn.BatchNorm2d(16).cuda()\n","        self.bn21 = nn.BatchNorm2d(32).cuda()\n","        self.bn22 = nn.BatchNorm2d(32).cuda()\n","\n","        self.bn31 = nn.BatchNorm2d(64).cuda()\n","        self.bn32 = nn.BatchNorm2d(64).cuda()\n","        self.bn33 = nn.BatchNorm2d(64).cuda()\n","        # self.logsoftmax = nn.LogSoftmax(dim=1).cuda()\n","\n","# \n","        \n","    def forward(self, x):\n","        \n","        out11 = self.relu(self.conv11(x))\n","        out12 = self.relu(self.bn11(out11)) #preactivation\n","        out12 = self.conv12(out12) #convolution\n","        out13 = self.conv13(self.relu(self.bn12(out12))) #residual connection\n","        out   = out11 + out13 #skip connection\n","        out   = self.maxpool(out)\n","\n","        out21 = self.relu(self.conv21(out))\n","        out22 = self.conv22(self.relu(self.bn21(out21))) #preactivation and convolution\n","        out23 = self.conv23(self.relu(self.bn22(out22))) #residual connections\n","        out   = out21 + out23 #skip connection\n","        out   = self.maxpool(out)\n","\n","        out31 = self.relu(self.conv31(out))\n","        out32 = self.conv32(self.relu(self.bn31(out31))) #preactivation and convolution\n","        out33 = self.conv33(self.relu(self.bn32(out32))) #residual connections\n","        out   = out31 + out33 #skip connection\n","        out   = self.avgpool(out)\n","       \n","        out = out.reshape(out.size(0), -1) \n","        out = self.fc(out) # we don't need sigmoid or other activation function at the end beacuse we will use nn.CrossEntropyLoss() (check documentation to understand why)\n","        # out = self.logsoftmax(out)\n","        return out \n","\n","model = Proposal(num_classes=10)\n","n_params = compute_model_params(model)\n","print(\"MyModel Parameters: \" + str(n_params))\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'learning_rate' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m LongCNN \u001b[39m=\u001b[39m LongConvNet()\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(LongCNN\u001b[39m.\u001b[39mparameters(),lr \u001b[39m=\u001b[39m learning_rate)\n\u001b[0;32m      4\u001b[0m loss_hist \u001b[39m=\u001b[39m train(LongCNN, train_loader, optimizer, num_epochs, model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlong_model.pkt\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(loss_hist)\n","\u001b[1;31mNameError\u001b[0m: name 'learning_rate' is not defined"]}],"source":["LongCNN = LongConvNet()\n","optimizer = torch.optim.Adam(LongCNN.parameters(),lr = learning_rate)\n","\n","loss_hist = train(LongCNN, train_loader, optimizer, num_epochs, model_name='long_model.pkt', device=device)\n","plt.plot(loss_hist)\n","plt.show()\n","\n","\n","print('Test accuracy is: {} %'.format(test(LongCNN, test_loader)))\n","# Create test data loader"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Different Optimizers"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'optim' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m MomCNN \u001b[39m=\u001b[39m BaseConvNet()\n\u001b[1;32m----> 2\u001b[0m optimizer_mom \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(MomCNN\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[0;32m      4\u001b[0m loss_hist \u001b[39m=\u001b[39m train(MomCNN, train_loader, optimizer, num_epochs, model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmom_model.pkt\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(loss_hist)\n","\u001b[1;31mNameError\u001b[0m: name 'optim' is not defined"]}],"source":["MomCNN = BaseConvNet()\n","optimizer_mom = optim.SGD(MomCNN.parameters(), lr=0.01, momentum=0.9)\n","\n","loss_hist = train(MomCNN, train_loader, optimizer, num_epochs, model_name='mom_model.pkt', device=device)\n","plt.plot(loss_hist)\n","plt.show()\n","\n","\n","print('Test accuracy is: {} %'.format(test(MomCNN, test_loader)))\n","# Create test data loader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["AdamCNN = BaseConvNet()\n","optimizer_adadelta = torch.optim.Adadelta(AdamCNN.parameters(),lr = 0.001)\n","\n","loss_hist = train(AdamCNN, train_loader, optimizer, num_epochs, model_name='adam_model.pkt', device=device)\n","plt.plot(loss_hist)\n","plt.show()\n","\n","\n","print('Test accuracy is: {} %'.format(test(AdamCNN, test_loader)))\n","# Create test data loader"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"h7QTVmaKQg4X"},"source":["# Ex. 2"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TLVQ_LI6kSmK"},"source":["# **Building your own efficient Convolutional Network architecture for SVHN**\n","\n","In the following,  you will need to build your own CNN architecture to predict digit numbers on the SVHN dataset. You are completely free to use any kind of layers and hyper-parameters for this purpose. Your goal is to acheive the maximum possible accuracy on the test set (the better, the higher score you'll get in the exercice). The only constraint is that your model should not contain more than 150K parameters. Below, we provide a simple code to compute the number of parameters in a model."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0TFCESJFn1xZ"},"source":["## Computing model parameters"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"dnSiO4xQn7qU"},"outputs":[],"source":["# Compute model paramters\n","def compute_model_params(model):\n","  params = 0\n","  for p in model.parameters():\n","    params+= p.numel()\n","  return params"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3333,"status":"ok","timestamp":1621274907073,"user":{"displayName":"Adria Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisOnK_2EZSTcp0aTuz0Ix6028ty6N2itoDgnMXvA=s64","userId":"10075760785236424538"},"user_tz":-120},"id":"XErSjYHEoKoz","outputId":"7b2f0991-43c1-4a1e-a7a9-f17a24969b66"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet Parameters: 153546\n","THIS MODEL CONTAINS 153K PARAMS, IT IS CONSIDERED NOT VALID FOR THE EXERCICE!!!!!!\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","# ResNet style network\n","class ResSim(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(ResSim, self).__init__()\n","        \n","        self.conv11 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv12 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","        \n","        self.conv21 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv22 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","        \n","        self.fc = nn.Linear(8*8*64, num_classes)\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, x):\n","        \n","        out11 = self.relu(self.conv11(x))\n","        out12 = self.relu(self.conv12(out11)) + out11\n","\n","        out = self.maxpool(out12)\n","\n","        out21 = self.relu(self.conv21(out)) \n","        out = self.relu(self.conv22(out21)) + out21\n","        out = self.maxpool(out)\n","        \n","        #print(out.shape)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        \n","        return out\n","# Initialize the model\n","model = ResSim(num_classes=10)\n","# Compute and print number of params\n","n_params = compute_model_params(model)\n","print(\"ResNet Parameters: \" + str(n_params)) ## \n","print(\"THIS MODEL CONTAINS 153K PARAMS, IT IS CONSIDERED NOT VALID FOR THE EXERCICE!!!!!!\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# My MODEL"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel Parameters: 550826\n"]}],"source":["class MyModel(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(MyModel, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,  padding=1).cuda()\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,  padding=1).cuda()\n","\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,  padding=1).cuda()\n","        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,  padding=1).cuda()\n","\n","        self.conv5 = nn.Conv2d(64, 128, kernel_size=3,  padding=1).cuda()\n","        self.conv6 = nn.Conv2d(128, 128, kernel_size=3,  padding=1).cuda()\n","        \n","        self.fc1 = nn.Linear(4*4*128, 128).cuda()\n","        self.fc2 = nn.Linear(128, num_classes).cuda()\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2).cuda()\n","        self.relu = nn.ReLU().cuda()\n","        self.soft_max = nn.Softmax(dim=1).cuda()\n","\n","        self.drop_out3 = nn.Dropout(p=0.3).cuda()\n","        self.drop_out4 = nn.Dropout(p=0.4).cuda()\n","        self.batch_norm1 = nn.BatchNorm2d(32).cuda()\n","        self.batch_norm2 = nn.BatchNorm2d(32).cuda()\n","        self.batch_norm3 = nn.BatchNorm2d(64).cuda()\n","\n","    def forward(self, x):\n","# conv, bat, conv, max, drop, conv, bat, conv, max, drop, conv, bat, conv, max, drop, flat, dense, drop, dense\n","        \n","        out = self.conv1(x)\n","        out = self.relu(out)\n","        out = self.batch_norm1(out)\n","        \n","        out = self.conv2(out)\n","        out = self.relu(out)\n","        out = self.maxpool(out)\n","        out = self.drop_out3(out)\n","        \n","        out = self.conv2(out)\n","        out = self.relu(out)\n","        out = self.batch_norm2(out)\n","\n","        out = self.conv3(out)\n","        out = self.relu(out)\n","        out = self.maxpool(out)\n","        out = self.drop_out3(out)\n","\n","        out = self.conv4(out)\n","        out = self.relu(out)\n","        out = self.batch_norm3(out)\n","        \n","        out = self.conv5(out)\n","        out = self.relu(out)\n","        out = self.maxpool(out)\n","        out = self.drop_out3(out)\n","\n","        out = out.reshape(out.size(0), -1) \n","        out = self.fc1(out)\n","        out = self.relu(out)\n","        out = self.drop_out3(out)\n","\n","        out = self.fc2(out)\n","        out = self.soft_max(out)\n","        return out \n","\n","\n","\n","\n","\n","model = MyModel(num_classes=10)\n","n_params = compute_model_params(model)\n","print(\"MyModel Parameters: \" + str(n_params))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Inception "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet Parameters: 1113226\n","THIS MODEL CONTAINS 153K PARAMS, IT IS CONSIDERED NOT VALID FOR THE EXERCICE!!!!!!\n"]}],"source":["class IncSim(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(IncSim, self).__init__()\n","        \n","        self.conv11 = nn.Conv2d(3, 64, kernel_size=1, stride=2, padding=0)\n","        self.conv12 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n","        self.conv13 = nn.Conv2d(3, 64, kernel_size=5, stride=2, padding=2)\n","        \n","        self.conv21 = nn.Conv2d(192, 128, kernel_size=1, stride=2, padding=0)\n","        self.conv22 = nn.Conv2d(192, 128, kernel_size=3, stride=2, padding=1)\n","        self.conv23 = nn.Conv2d(192, 128, kernel_size=5, stride=2, padding=2)\n","        \n","        self.fc = nn.Linear(8*8*384, num_classes)\n","        \n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, x):\n","        \n","        #Inc 1 \n","        out11 = self.relu(self.conv11(x))\n","        out12 = self.relu(self.conv12(x))\n","        out13 = self.relu(self.conv13(x))\n","        \n","        out1a = [out11, out12, out13]\n","        out1a = torch.cat(out1a,dim=1)\n","        \n","        #Inc 12\n","        out21 = self.relu(self.conv21(out1a))\n","        out22 = self.relu(self.conv22(out1a))\n","        out23 = self.relu(self.conv23(out1a))\n","        \n","        out2a = [out21, out22, out23]\n","        out2a = torch.cat(out2a,1)\n","        \n","        out = out2a.view(out2a.size(0), -1)\n","        out = self.fc(out)\n","        \n","        return out\n","model = IncSim(num_classes=10)\n","# Compute and print number of params\n","n_params = compute_model_params(model)\n","print(\"ResNet Parameters: \" + str(n_params)) ## \n","print(\"THIS MODEL CONTAINS 153K PARAMS, IT IS CONSIDERED NOT VALID FOR THE EXERCICE!!!!!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnJBuRZVjpOl"},"outputs":[],"source":["'''\n","1. Design and implement your own CNN. Given that the number of parameters must be small, you can check some papers focused on efficient CNN architectures and get some ideas.\n","  - MobileNet: https://arxiv.org/abs/1704.04861\n","  - MobileNet V2: https://arxiv.org/pdf/1801.04381.pdf\n","  - SqueezeNet: https://arxiv.org/abs/1602.07360\n","  - ShuffleNet: https://arxiv.org/abs/1707.01083\n","  - ESPNet V2: https://arxiv.org/abs/1811.11431\n","2. Train it and test it on SVHN using the provided code.\n","3. Discuss what approaches have you tried, why, and which ones have shown to be more beneficial.\n","'''\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VObbYfbsQkls"},"source":["## Sol. 2"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\alber\\OneDrive - estudiant.upf.edu\\UNI (upf)\\3rd yaaaaar\\DeepLearning\\DeepLearning\\P3\n"]}],"source":["!cd \"\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wlKMweHXPO1z"},"source":["### Define your own model and check the number of total parameters"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["4.0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["32/8"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":1027,"status":"ok","timestamp":1588763623846,"user":{"displayName":"Adria Ruiz","photoUrl":"","userId":"10075760785236424538"},"user_tz":-120},"id":"xMxY47BLpEPG","outputId":"7b6b8051-30d5-4161-d8cc-8fd23c815d0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel Parameters: 2186\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","#Mobilenet Style Architecture\n","class MyModel(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(MyModel, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","\n","\n","        self.fc= nn.Linear(2*2*32, num_classes)\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2) # 16x16\n","        self.relu = nn.ReLU()\n","\n","                \n","\n","                \n","    def forward(self, x): \n","        out = self.relu(self.conv1(x))\n","        out = self.maxpool(out)\n","        out = self.maxpool(out)\n","        out = self.maxpool(out)\n","        out = self.maxpool(out)\n","        #Reshape\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","        \n","\n","        \n","\n","\n","model = MyModel(num_classes=10)\n","n_params = compute_model_params(model)\n","print(\"MyModel Parameters: \" + str(n_params))\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel Parameters: 160202\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","#Mobilenet Style Architecture\n","class MyModel(nn.Module):\n","    def __init__(self, num_classes=10):\n","        \n","        super(MyModel, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","        \n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","\n","        self.fc1= nn.Linear(2*2*128, 128)\n","        self.fc2= nn.Linear(128, num_classes)\n","        \n","        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2) # 16x16\n","        self.relu = nn.ReLU()\n","\n","                \n","\n","                \n","    def forward(self, x): \n","        out = self.relu(self.conv1(x))\n","        out = self.maxpool(out)\n","        out = self.relu(self.conv2(out))\n","        out = self.maxpool(out)\n","        out = self.relu(self.conv3(out))\n","        out = self.maxpool(out)\n","        #Reshape\n","        out = out.view(out.size(0), -1)\n","        out = self.relu(self.fc1(out))\n","        out = self.fc2(out)\n","        return out        \n","\n","\n","model = MyModel(num_classes=10)\n","n_params = compute_model_params(model)\n","print(\"MyModel Parameters: \" + str(n_params))\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3dangurPPcgm"},"source":["### Train your model on SVHN\n","It is not allowed to change training hyper-parameters such as learning rate, batch size or number of epochs. You can only modify the architecture definition."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Ln0tdN7Iu3hu"},"outputs":[],"source":["## Create SVHN database\n","\n","# All the data will be loaded from the provided file in Data/mnist.t\n","import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import scipy.io as sio\n","\n","import numpy as np\n","\n","# Mount Google Drive\n","\n","data_path = 'Data'\n","results_path = 'Results'\n","\n","#Making native class loader\n","class SVHN(torch.utils.data.Dataset):\n","    # Initialization method for the dataset\n","    def __init__(self,dataDir = data_path+'/svhn/train_32x32.mat',transform = None):\n","        mat_loaded = sio.loadmat(dataDir)\n","        self.data = mat_loaded['X']\n","        self.labels = mat_loaded['y'].squeeze()\n","        self.labels -= self.labels.min()\n","        self.transform = transform\n","     # What to do to load a single item in the dataset ( read image and label)    \n","    def __getitem__(self, index):\n","        data = self.data[:,:,:,index]\n","        lbl = self.labels[index]\n","        \n","        data = Image.fromarray(data)\n","        # Apply a trasnformaiton to the image if it is indicated in the initalizer\n","        if self.transform is not None : \n","            data = self.transform(data)\n","        \n","        # return the image and the label\n","        return data,lbl\n","    \n","        pass\n","    \n","    # Return the number of images\n","    def __len__(self):\n","        return self.data.shape[3]\n","\n","# Create train data loader\n","tr = tf.Compose([\n","        tf.ToTensor(), \n","        tf.Normalize(mean = [.5], std = [.5])\n","        ])\n","SVHNTrain = SVHN(data_path+'/svhn/train_32x32.mat',tr)\n","train_loader = torch.utils.data.DataLoader(dataset=SVHNTrain,\n","                                               batch_size=256, \n","                                               shuffle=True)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"ccmWoqr5u9Xj"},"outputs":[],"source":["# Train function\n","def train(CNN, train_loader, optimizer, num_epochs=5, model_name='model.ckpt', device='cpu', scheduler=None,criterion=nn.CrossEntropyLoss()):\n","    CNN.train() # Set the model in train mode\n","    if scheduler is not None: scheduler = lrs.ExponentialLR(optimizer, gamma=0.95) \n","    total_step = len(train_loader)\n","    losses_list = []\n","    \n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        loss_avg = 0\n","        nBatches = 0\n","        for i, (images, labels) in enumerate(train_loader):\n","            # Get batch of samples and labels\n","            images = images.to(device)\n","            labels = labels.type(torch.LongTensor).to(device)\n","\n","            # Forward pass\n","            outputs = CNN(images)\n","            loss = criterion(outputs, labels)\n","            \n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            losses_list.append(loss.cpu().item())\n","            loss_avg += loss.cpu().item()\n","            nBatches+=1\n","            if (i+1) % 100 == 0:\n","                if scheduler is not None:\n","                    for param_group in optimizer.param_groups:\n","                        print(\"Current learning rate is: {}\".format(param_group['lr']))\n","                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches))\n","        if scheduler is not None: scheduler.step()\n","        \n","\n","        # losses_list.append(loss_avg / nBatches)\n","        torch.save(CNN.state_dict(), results_path+ '/' + model_name)\n","          \n","    return losses_list \n","\n","# Test funcion\n","def test(CNN, test_loader):\n","  with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            # get network predictions\n","            outputs = CNN(images)\n","\n","            # get predicted class\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            # compare with the ground-truth\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        # return accuracy\n","        return 100 * correct / total"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["def get_batch_hard(CNN, train_loader, prop=0.7, device='cpu'):\n","    with torch.no_grad():\n","        losses = []\n","        for images, labels in train_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            # get network predictions\n","            outputs = CNN(images)\n","            # get loss\n","            loss = criterion(outputs, labels)\n","            losses.append(loss)\n","        losses = torch.stack(losses)\n","        losses = losses.cpu().numpy()\n","        idx = np.argsort(losses)[::-1]\n","        idx_hard_batches = idx[:int(len(train_loader)*prop)]\n","        return idx_hard_batches\n","    \n","def train_hard(CNN, train_loader, optimizer, num_epochs=5, prop=0.7, model_name='model.ckpt', device='cpu', scheduler=None):\n","\n","# get the batches to run through the model\n","    idx_hard = get_batch_hard(CNN, train_loader, prop=prop, device=device)\n","    CNN.train() # Set the model in train mode\n","    if scheduler is not None: scheduler = lrs.ExponentialLR(optimizer, gamma=0.95) \n","    total_step = len(train_loader)\n","    losses_list = []\n","    \n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        loss_avg = 0\n","        nBatches = 0\n","        for i, (images, labels) in enumerate(train_loader):\n","            if i not in idx_hard: continue\n","            # Get batch of samples and labels\n","            images = images.to(device)\n","            labels = labels.type(torch.LongTensor).to(device)\n","\n","            # Forward pass\n","            outputs = CNN(images)\n","            loss = criterion(outputs, labels)\n","            \n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            losses_list.append(loss.cpu().item())\n","            loss_avg += loss.cpu().item()\n","            nBatches+=1\n","            if (i+1) % 100 == 0:\n","                if scheduler is not None:\n","                    for param_group in optimizer.param_groups:\n","                        print(\"Current learning rate is: {}\".format(param_group['lr']))\n","                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches))\n","        if scheduler is not None: scheduler.step()\n","        \n","\n","        # losses_list.append(loss_avg / nBatches)\n","        torch.save(CNN.state_dict(), results_path+ '/' + model_name)\n","          \n","    return losses_list "]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["max_degree = 8\n","tr_model = tf.Compose([\n","        tf.ToTensor(), \n","        tf.Normalize(mean = [.5], std = [.5]),\n","        tf.RandomRotation(max_degree),\n","        tf.RandomAffine(degrees=0, translate=(0, 0.1), scale=(0.95, 1.05), shear=0.15)\n","        ])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["max_degree = 10\n","\n","SVHNTrain_gray = SVHN(data_path+'/svhn/train_32x32.mat',tr_model)\n","SVHNTest_gray = SVHN(data_path+'/svhn/test_32x32.mat',tr_model)\n","\n","train_loader_gray = torch.utils.data.DataLoader(dataset=SVHNTrain_gray,\n","                                               batch_size=256, \n","                                               shuffle=True)\n","\n","test_loader_gray = torch.utils.data.DataLoader(dataset=SVHNTest_gray,\n","                                               batch_size=256, \n","                                               shuffle=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["TRain the model"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"9vib9IY2vAkP"},"outputs":[{"name":"stdout","output_type":"stream","text":["number of parameters: 131402\n","Epoch [1/10], Step [100/287], Loss: 1.1771\n","Epoch [1/10], Step [200/287], Loss: 0.8171\n","Epoch [1/10], Step [287/287], Loss: 0.6794\n","Epoch [2/10], Step [100/287], Loss: 0.3037\n","Epoch [2/10], Step [200/287], Loss: 0.2940\n","Epoch [2/10], Step [287/287], Loss: 0.2879\n","Epoch [3/10], Step [100/287], Loss: 0.2311\n","Epoch [3/10], Step [200/287], Loss: 0.2350\n","Epoch [3/10], Step [287/287], Loss: 0.2330\n","Epoch [4/10], Step [100/287], Loss: 0.2040\n","Epoch [4/10], Step [200/287], Loss: 0.2021\n","Epoch [4/10], Step [287/287], Loss: 0.2016\n","Epoch [5/10], Step [100/287], Loss: 0.1698\n","Epoch [5/10], Step [200/287], Loss: 0.1779\n","Epoch [5/10], Step [287/287], Loss: 0.1794\n","Epoch [6/10], Step [100/287], Loss: 0.1510\n","Epoch [6/10], Step [200/287], Loss: 0.1505\n","Epoch [6/10], Step [287/287], Loss: 0.1578\n","Epoch [7/10], Step [100/287], Loss: 0.1392\n","Epoch [7/10], Step [200/287], Loss: 0.1414\n","Epoch [7/10], Step [287/287], Loss: 0.1439\n","Epoch [8/10], Step [100/287], Loss: 0.1127\n","Epoch [8/10], Step [200/287], Loss: 0.1196\n","Epoch [8/10], Step [287/287], Loss: 0.1250\n","Epoch [9/10], Step [100/287], Loss: 0.1016\n","Epoch [9/10], Step [200/287], Loss: 0.1090\n","Epoch [9/10], Step [287/287], Loss: 0.1119\n","Epoch [10/10], Step [100/287], Loss: 0.0870\n","Epoch [10/10], Step [200/287], Loss: 0.0927\n","Epoch [10/10], Step [287/287], Loss: 0.0964\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#Train MyModel\n","# my_model = MyModel(num_classes=10)\n","# my_model = IncSim()\n","# my_model = LongConvNet()\n","my_model = Proposal()\n","# criterion = nn.NLLLoss()\n","criterion = nn.CrossEntropyLoss()\n","\n","#Initialize optimizer \n","learning_rate = .001\n","optimizer = torch.optim.Adam(my_model.parameters(),lr = learning_rate)\n","\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","my_model = my_model.to(device)\n","\n","print('number of parameters: ' + str(compute_model_params(my_model)))\n","\n","losses_list = train(my_model, train_loader, optimizer, num_epochs=10, model_name='proposal_sched_exp.ckpt', device=device,criterion=criterion)\n","plt.plot(losses_list)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["losses_list = train_hard(my_model, train_loader, optimizer, num_epochs=10, model_name='proposal_sched_exp.ckpt', device=device, scheduler=\"pepesito\")\n","plt.plot(losses_list)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s4ilm-FoPmLX"},"source":["### Test your model\n","As a reference, 93% of accuracy can be easily achieved by using only ~55000 parameters."]},{"cell_type":"code","execution_count":85,"metadata":{"id":"LHT86IPSzOYi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy MyNet: 92.73970497848802\n"]}],"source":["# Show results for all the trained models\n","data_path = 'Data'\n","SVHNTest = SVHN(data_path+'/svhn/test_32x32.mat',tr)\n","test_loader = torch.utils.data.DataLoader(dataset=SVHNTest,\n","                                               batch_size=256, \n","                                               shuffle=True)\n","\n","#\n","my_net = Proposal()\n","my_net.load_state_dict(torch.load(results_path + '/proposal_sched_exp.ckpt'))\n","my_net.cuda()\n","acc = test(my_net, test_loader) \n","\n","print('Accuracy MyNet: ' + str(acc))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"S7UMjGA9TOUM"},"source":["# Ex. 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXvqONt8TNuc"},"outputs":[],"source":["'''\n","1. Use the implemented architecture in the previous exercice to solve the transfer learning\n","   task provided in the examples.\n","2. Try to fine-tune not only the last layer for the CNN but a larger subset of parameters.\n","2. Report the test accuracy in each case and discuss the results. \n","'''"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o31sdIuJUHex"},"source":["## Sol. 3"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bSGN1MHVIQBJ"},"source":["### Initialize DataLoaders for Transfer Learning experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lftsNbnEHeoh"},"outputs":[],"source":["# Big dataset with numbers from 1 to 8\n","SVHNTrain_TL = SVHN(data_path+'/svhn_tl/tl_train_32x32.mat',tr)\n","tl_train_loader = torch.utils.data.DataLoader(dataset=SVHNTrain_TL,\n","                                               batch_size=256, \n","                                               shuffle=True)\n","\n","# 200 samples of 0s and 9s\n","SVHNTrain_TL_0_9 = SVHN(data_path+'/svhn_tl/tl_train_9_10_32x32.mat',tr)\n","tl_train_loader_0_9 = torch.utils.data.DataLoader(dataset=SVHNTrain_TL_0_9,\n","                                                  batch_size=64, \n","                                                  shuffle=True)\n","# Test dataset with 0 and 9s\n","SVHNTest_TL_0_9 = SVHN(data_path+'/svhn_tl/tl_test_9_10_32x32.mat',tr)\n","tl_test_loader_0_9 = torch.utils.data.DataLoader(dataset=SVHNTest_TL_0_9,\n","                                                  batch_size=64, \n","                                                  shuffle=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VXbLlY4aC4Ga"},"source":["### Pre-train your model with the big dataset with numbers from 1 to 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2zitIY5tJRg"},"outputs":[],"source":["#Train ResNet\n","resnet_tl = MyModel(num_classes=8)\n","#Initialize optimizer \n","learning_rate = .1\n","optimizer = torch.optim.SGD(resnet_tl.parameters(),lr = learning_rate, weight_decay=1e-5, momentum=0.9)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","resnet_tl = resnet_tl.to(device)\n","\n","losses_it = train(resnet_tl, tl_train_loader, optimizer, num_epochs=10, model_name='tl_mynet_svhn.ckpt', device=device)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"X0HrjNVIFNKN"},"source":["### Fine-tune the pretrained network with the small dataset of 9s and 0s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDemFpsnsw4J"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"albertkernel","language":"python","name":"albertkernel"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
