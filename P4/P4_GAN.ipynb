{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IvcOz1eTrxRx"
      },
      "source": [
        "# **Deep Generative Models: Variational Autoencoders and Generative Adversarial Networks**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EvWs2XIYNfhg"
      },
      "source": [
        "# **CK Dataset**\n",
        "In the following exercices, you will work with images extracted from the CK dataset: http://www.jeffcohn.net/wp-content/uploads/2020/02/Cohn-Kanade_Database.pdf.pdf\n",
        "\n",
        "It contains gray-scale images of human faces.\n",
        "\n",
        "The dataset is provided in the folder Data/faces/ in .mat format.\n",
        "In the following we provide a Dataset class in pytorch to load images from this database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "5kE5D0hh1Ndz",
        "outputId": "9483add6-4ad6-45c9-f5df-a2326394b6d9"
      },
      "outputs": [],
      "source": [
        "## Create a Custom Dataset for CK database\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "# Mount Google Drive\n",
        "\n",
        "try:\n",
        "    print(\"Currently on path\", base_path)\n",
        "except NameError:\n",
        "    base_path = os.getcwd().replace('\\\\', '/')\n",
        "    print(\"Path is not defined, initialized to\", base_path)\n",
        "\n",
        "data_path = base_path+'/Data/'\n",
        "results_path = base_path+'/Results/'\n",
        "\n",
        "# All the data will be loaded from the provided file in Data/mnist.t\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import scipy.io as sio\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "\n",
        "\n",
        "#Making native class loader\n",
        "class FacesDB(torch.utils.data.Dataset):\n",
        "    # Initialization method for the dataset\n",
        "    def __init__(self,dataDir = data_path+'/faces/face_ims_64x64.mat', transform = None):\n",
        "        mat_loaded = sio.loadmat(dataDir)\n",
        "        self.data = mat_loaded['X']\n",
        "        self.transform = transform\n",
        "\n",
        "    # What to do to load a single item in the dataset ( read image and label)\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[:,:,0,index]\n",
        "        data = Image.fromarray(data,mode='L')\n",
        "        # Apply a trasnformaiton to the image if it is indicated in the initalizer\n",
        "        if self.transform is not None :\n",
        "            data = self.transform(data)\n",
        "\n",
        "        # return the image and the label\n",
        "        return data\n",
        "\n",
        "    # Return the number of images\n",
        "    def __len__(self):\n",
        "        return self.data.shape[3]\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "tr = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "faces_db = FacesDB(data_path+'/faces/face_ims_64x64.mat',tr)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=faces_db,\n",
        "                                           batch_size=256,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# Mini-batch images\n",
        "images = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "image = images[0,:,:,:].repeat(3,1,1)\n",
        "print(image.permute(1,2,0).squeeze().numpy().shape)\n",
        "plt.imshow(image.permute(1,2,0).squeeze().numpy())\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CVA6m-IgNace"
      },
      "source": [
        "# Ex. 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "y1yTECVjDVmf",
        "outputId": "5285d823-5808-45c8-bbd9-c18510b02767"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1. Following the example of the MNIST , train a VAE with the images we have provided for the CK dataset.\n",
        "2. For every two epochs during training:\n",
        "  2.1. Visualize a set of reconstructed images and compute the reconstruction error over the whole dataset\n",
        "  2.2. Generate and show a set of images from random noise z.\n",
        "  2.3. Visualize a set of generated images by interpolating over the latent space z.\n",
        "  2.4. Discuss the different visualizations by analysing their relation with the evolution of the reconstruction loss and the KL regularization term.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V496_LD36ZLY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Convolution + BatchNormnalization + ReLU block for the encoder\n",
        "class ConvBNReLU(nn.Module):\n",
        "  def __init__(self,in_channels, out_channels, pooling=False):\n",
        "    super(ConvBNReLU, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,\n",
        "                          padding = 1)\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    self.pool = None\n",
        "    if(pooling):\n",
        "      self.pool = nn.AvgPool2d(2,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    if(self.pool):\n",
        "      out = self.pool(x)\n",
        "    else:\n",
        "      out = x\n",
        "    out = self.relu(self.bn(self.conv(out)))\n",
        "    return out\n",
        "\n",
        "#  BatchNormnalization + ReLU block + Convolution for the decoder\n",
        "class BNReLUConv(nn.Module):\n",
        "  def __init__(self,in_channels, out_channels, pooling=False):\n",
        "    super(BNReLUConv, self).__init__()\n",
        "    self.bn = nn.BatchNorm2d(in_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,\n",
        "                          padding = 1)\n",
        "\n",
        "    self.pool = None\n",
        "    if(pooling):\n",
        "      self.pool = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.relu(self.bn(x))\n",
        "    if(self.pool):\n",
        "      out = self.pool(out)\n",
        "    out = self.conv(out)\n",
        "    return out\n",
        "\n",
        "# Encoder definition with 3 COnv-BN-ReLU blocks and fully-connected layer\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,out_features,base_channels=16):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.layer1 = ConvBNReLU(1,base_channels,pooling=False)\n",
        "    self.layer2 = ConvBNReLU(base_channels,base_channels*2,pooling=True)\n",
        "    self.layer3 = ConvBNReLU(base_channels*2,base_channels*4,pooling=True)\n",
        "    self.fc = nn.Linear(16*16*base_channels*4,out_features)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    return self.fc(out.view(x.shape[0],-1))\n",
        "\n",
        "# Decoder definition with a fully-connected layer and 3 BN-ReLU-COnv blocks and\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,out_features,base_channels=16):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.base_channels = base_channels\n",
        "    self.fc = nn.Linear(out_features,16*16*base_channels*4)\n",
        "    self.layer3 = BNReLUConv(base_channels*4,base_channels*2,pooling=True)\n",
        "    self.layer2 = BNReLUConv(base_channels*2,base_channels,pooling=True)\n",
        "    self.layer1 = BNReLUConv(base_channels,1,pooling=False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc(x)\n",
        "    out = out.view(x.shape[0],self.base_channels*4,16,16)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer1(out)\n",
        "    return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QBrV-9x6ZLa",
        "outputId": "7c025646-4004-4f40-c24d-44e75a21a88b"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, out_features=64,base_channels=16):\n",
        "    super(VAE, self).__init__()\n",
        "    # Initialize the encoder and decoder using a dimensionality out_features for the vector z\n",
        "    self.out_features = out_features\n",
        "    self.encoder = Encoder(out_features*2,base_channels)\n",
        "    self.decoder = Decoder(out_features,base_channels)\n",
        "\n",
        "  # function to obtain the mu and sigma of z for a samples x\n",
        "  def encode(self,x):\n",
        "    aux = self.encoder(x)\n",
        "    # get z mean\n",
        "    z_mean = aux[:,0:self.out_features]\n",
        "    # get z variance\n",
        "    z_log_var = aux[:,self.out_features::]\n",
        "    return z_mean, z_log_var\n",
        "\n",
        "  # function to generate a random sample z given mu and sigma\n",
        "  def sample_z(self,z_mean,z_log_var):\n",
        "    z_std = z_log_var.mul(0.5).exp()\n",
        "    samples_unit_normal = torch.randn_like(z_mean)\n",
        "    samples_z = samples_unit_normal*z_std + z_mean\n",
        "    return samples_z\n",
        "\n",
        "  def forward(self,x):\n",
        "    z_mean, z_log_var = self.encode(x)\n",
        "    samples_z = self.sample_z(z_mean,z_log_var)\n",
        "    x_rec = self.decoder(samples_z)\n",
        "    return x_rec, z_mean, z_log_var\n",
        "\n",
        "# Print summary ofCmode\n",
        "print('MNISTK VAE Definition')\n",
        "vae = VAE(32)\n",
        "print(vae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOHoQsEY6ZLb"
      },
      "outputs": [],
      "source": [
        "## Kullback-Leibler regularization computation\n",
        "def kl_divergence(z_mean,z_log_var):\n",
        "  kl_loss = 0.5 * torch.sum(  (torch.exp(z_log_var) + z_mean**2 - 1.0 - z_log_var),axis=1)\n",
        "  return kl_loss.mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TPhaB5uN5nub"
      },
      "source": [
        "## Sol. 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhsDbuhe6ZLe",
        "outputId": "86672e03-5b69-4145-eb27-ee10e0526ce0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "For every two epochs during training:\n",
        "  2.1. Visualize a set of reconstructed images and compute the reconstruction error over the whole dataset\n",
        "  2.2. Generate and show a set of images from random noise z.\n",
        "  2.3. Visualize a set of generated images by interpolating over the latent space z.\n",
        "  2.4. Discuss the different visualizations by analysing their relation with the evolution of the reconstruction loss and the KL regularization term.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBaH6l6i6ZLg"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "\n",
        "def alternate_rec_ref(rec_images, ref_images):\n",
        "    interleaved_images = np.empty((2 * len(ref_images), 3, 64, 64), dtype=np.float32)\n",
        "    interleaved_images[0::2] = ref_images\n",
        "    interleaved_images[1::2] = rec_images\n",
        "\n",
        "    # Convert the interleaved array to a PyTorch tensor\n",
        "    tensor_images = torch.from_numpy(interleaved_images)\n",
        "\n",
        "    # Create the grid of images\n",
        "    plt.figure(figsize=(9,9))\n",
        "    plt.title('Reconstructed Images')\n",
        "    image_grid = make_grid(tensor_images.view(32,3,64,64), nrow=8, padding=1)\n",
        "    plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n",
        "    plt.show()\n",
        "\n",
        "def generate_images(vae, n_samples=64, device='cpu'):\n",
        "    ### Generate random samples\n",
        "    vae.eval()\n",
        "    # Random vectors z~N(0,I)\n",
        "    z = torch.randn((n_samples,vae.out_features)).to(device)\n",
        "\n",
        "    # Genearte images with the decoder from the random vectors\n",
        "    x_rec = vae.decoder(z)\n",
        "\n",
        "    # Show synthetic images\n",
        "    plt.figure(figsize=(9,9))\n",
        "    plt.title('Generated Images')\n",
        "    image_grid = make_grid(x_rec.cpu(),nrow=8,padding=1)\n",
        "    plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n",
        "\n",
        "def interpolate_images(model, n_samples=64, n_iterpolations=50, device='cpu'):\n",
        "    ### Generate random samples\n",
        "    ### Generate random samples\n",
        "    model.eval()\n",
        "\n",
        "    # Sample a set of pairs z_init and z_final\n",
        "    z_init = torch.randn((n_samples,vae.out_features)).to(device)*2\n",
        "    z_final = torch.randn((n_samples,vae.out_features)).to(device)*2\n",
        "\n",
        "    # Compute interpolations between z_init and z_final\n",
        "    # and generate an image for each interpolation.\n",
        "    interpolation_images = []\n",
        "    for interp in range(0,n_iterpolations):\n",
        "        interp_0_1 = float(interp) / (n_iterpolations-1)\n",
        "        z = z_init*interp_0_1 + z_final*(1-interp_0_1)\n",
        "        x_rec = decoder.decoder(z)\n",
        "        image_grid = make_grid(x_rec.cpu(),nrow=8,padding=1)\n",
        "        image_grid = image_grid.permute(1,2,0).detach().numpy()\n",
        "        # save the generated images in a list\n",
        "        interpolation_images.append((image_grid*255.0).astype(np.uint8))\n",
        "\n",
        "    # Concatenate the inversion of the list to generate a \"loop\" animation\n",
        "    interpolation_images += interpolation_images[::-1]\n",
        "\n",
        "    # Generate and visualize a give showing the interpolation results.\n",
        "    imname = results_path+'/vae_interpolation_CK.gif'\n",
        "    imageio.mimsave(imname, interpolation_images, fps=25)\n",
        "\n",
        "    with open(imname,'rb') as f:\n",
        "        display(Image(data=f.read(), format='png',width=512,height=512))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0EjU_Us6ZLh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# Train function stopping at every 2 epochs for the requested visualizations\n",
        "def train_VAE(vae,  train_loader, optimizer, kl_weight=0.001, num_epochs=10, model_name='vae_mnist.ckpt', device='cpu'):\n",
        "    vae.to(device)\n",
        "    vae.train() # Set the model in train mode\n",
        "    total_step = len(train_loader)\n",
        "    losses_list = []\n",
        "    criterion = nn.MSELoss() # Use mean-squared error to compare the original and reconstructe images\n",
        "\n",
        "    total_batch_size = len(train_loader)\n",
        "    # Iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Iterate the dataset\n",
        "        rec_loss_avg = 0\n",
        "        kl_loss_avg = 0\n",
        "        nBatches = 0\n",
        "        keep_samples = np.random.choice(total_batch_size, 16, replace=False)\n",
        "        ref_images = np.array([])\n",
        "        rec_images = np.array([])\n",
        "        total_rec_loss = 0\n",
        "        for i, (images) in enumerate(train_loader):\n",
        "            # Get batch of samples and labels\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass (get encoder variables and reconstructed images)\n",
        "            x_rec, z_mean, z_log_var = vae(images)\n",
        "            reconstruction_loss = criterion(x_rec, images) # Reconstruction loss (x,x_rec)\n",
        "\n",
        "            if epoch % 2 == 0:\n",
        "                total_rec_loss += reconstruction_loss.cpu().item()\n",
        "                if i in keep_samples:\n",
        "                    idx = random.randint(0,images.shape[0]-1)\n",
        "                    rec_images = np.append(rec_images, x_rec[idx,:,:,:].repeat(3,1,1).permute(1,2,0).squeeze().numpy())\n",
        "                    ref_images = np.append(ref_images, images[idx,:,:,:].repeat(3,1,1).permute(1,2,0).squeeze().numpy())\n",
        "\n",
        "\n",
        "            kl_loss = kl_divergence(z_mean, z_log_var) # Compute KL divergecnes KL( N(mu_x,sigma_x) || N(0,I))\n",
        "\n",
        "            # Backward and optimize reconstruction loss and kl regularization\n",
        "            optimizer.zero_grad()\n",
        "            loss = reconstruction_loss + kl_loss*kl_weight # we use a weight to balance the importance of the KL loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            rec_loss_avg += reconstruction_loss.cpu().item()\n",
        "            kl_loss_avg += kl_loss.cpu().item()\n",
        "\n",
        "            nBatches+=1\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Rec. Loss: {:.4f}, KL Loss: {:.4f}'\n",
        "                       .format(epoch+1, num_epochs, i+1, total_step, rec_loss_avg / nBatches, kl_loss_avg / nBatches))\n",
        "        print ('Epoch [{}/{}], Step [{}/{}], Rec. Loss: {:.4f}, KL Loss: {:.4f}'\n",
        "                       .format(epoch+1, num_epochs, i+1, total_step, rec_loss_avg / nBatches, kl_loss_avg / nBatches))\n",
        "        losses_list.append(rec_loss_avg / nBatches)\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            print(\"-----------------------Reconstruced images:\\n-----------------------\")\n",
        "            # create a grid of images of 4 rows and 8 columns (32 images in total) where you use the images in ref_images and rec_images\n",
        "            # intercalated (ref,rec,ref,rec,ref,rec,ref,rec,ref,rec,ref,rec,ref,rec,ref,rec)\n",
        "            plt.figure(figsize=(9,9))\n",
        "            plt.title('Reconstructed Images')\n",
        "            image_grid = make_grid(torch.from_numpy(np.concatenate((ref_images,rec_images))).view(32,3,64,64),nrow=8,padding=1)\n",
        "            plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n",
        "            plt.show()\n",
        "            print(\"For which the corresponding MSE is: \")\n",
        "            print(criterion(torch.from_numpy(np.concatenate((ref_images,rec_images))).view(32,3,64,64),torch.from_numpy(np.concatenate((ref_images,rec_images))).view(32,3,64,64)).item())\n",
        "\n",
        "\n",
        "            print(\"-----------------------Generated images:\\n-----------------------\")\n",
        "            generate_images(vae, n_samples=64, device=device)\n",
        "            print(\"-----------------------Interpolated images:\\n-----------------------\")\n",
        "            interpolate_images(vae, n_samples=64, n_iterpolations=50, device=device)\n",
        "\n",
        "            # z = torch.randn_like(z_mean)\n",
        "            # x_rec = vae.decoder(z)\n",
        "            # plt.figure(figsize=(9,9))\n",
        "            # plt.title('Generated Images')\n",
        "            # image_grid = make_grid(x_rec.cpu(),nrow=4,padding=1)\n",
        "            # plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n",
        "            # plt.show()\n",
        "\n",
        "\n",
        "    # save trained model\n",
        "    torch.save(vae.state_dict(), results_path+ '/' + model_name)\n",
        "\n",
        "    return losses_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FhQbpBkQ5ux0"
      },
      "source": [
        "# Ex. 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "J5zT1eRf5ux4",
        "outputId": "9236d987-b00b-45e1-9669-07756d7a9ea5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1. Following the example of the MNIST , train a GAN with the images we have provided for the CK dataset.\n",
        "2. For every two epochs during training:\n",
        "  2.1. Generate and show a set of images from random noise z.\n",
        "  2.2. Visualize a set of generated images by interpolating over the latent space z.\n",
        "  2.3. Discuss the different visualizations by analysing their relation between their quality and the evolution of the discriminator and generator losses.\n",
        "Compare the results with the ones obtained with VAEs\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFHVpZlA6ZLj"
      },
      "outputs": [],
      "source": [
        "# Discriminator similar to VAE encoder\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, base_channels=16):\n",
        "    super(Discriminator, self).__init__()\n",
        "    # last fully connected layer acts as a a binary classifier\n",
        "    self.classifier = Encoder(1, base_channels)\n",
        "\n",
        "  # Forward pass obtaining the discriminator probability\n",
        "  def forward(self,x):\n",
        "    out = self.classifier(x)\n",
        "    # use sigmoid to get the real/fake image probability\n",
        "    return torch.sigmoid(out)\n",
        "\n",
        "# Generator is defined as VAE decoder\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self,in_features,base_channels=16):\n",
        "    super(Generator, self).__init__()\n",
        "    self.base_channels = base_channels\n",
        "    self.in_features = in_features\n",
        "    self.decoder = Decoder(in_features,base_channels)\n",
        "\n",
        "  # Generate an image from vector z\n",
        "  def forward(self,z):\n",
        "    return torch.sigmoid(self.decoder(z))\n",
        "\n",
        "  # Sample a set of images from random vectors z\n",
        "  def sample(self,n_samples=256,device='cpu'):\n",
        "    samples_unit_normal = torch.randn((n_samples,self.in_features)).to(device)\n",
        "    return self.decoder(samples_unit_normal)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vUrqAof5JRjH"
      },
      "source": [
        "## Sol. 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juLwqE--6ZLk",
        "outputId": "fb19ba87-5c02-46c0-8d1c-bf07e6927413"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1. Following the example of the MNIST , train a GAN with the images we have provided for the CK dataset.\n",
        "2. For every two epochs during training:\n",
        "  2.1. Generate and show a set of images from random noise z.\n",
        "  2.2. Visualize a set of generated images by interpolating over the latent space z.\n",
        "  2.3. Discuss the different visualizations by analysing their relation between their quality and the evolution of the discriminator and generator losses.\n",
        "Compare the results with the ones obtained with VAEs\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvIQZjye6ZLl"
      },
      "outputs": [],
      "source": [
        "def generate_gan(generator, n_samples=16, device='cpu'):\n",
        "    generator = Generator(32)\n",
        "    generator.load_state_dict(torch.load(results_path+'/gan_ck.ckpt'))\n",
        "    generator = generator.to(device)\n",
        "\n",
        "\n",
        "    generated_images = generator.sample(n_samples,device=device)\n",
        "    plt.figure(figsize=(9,9))\n",
        "    plt.title('Generated Images')\n",
        "    image_grid = make_grid(generated_images.cpu(),nrow=4,padding=1)\n",
        "    plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n",
        "    plt.show()\n",
        "\n",
        "def interpolate_gan(generator, n_samples = 64, n_iterpolations =50, device='cpu'):\n",
        "    ### Generate random samples\n",
        "    generator = Generator(32)\n",
        "    generator.load_state_dict(torch.load(results_path+'/gan_ck.ckpt'))\n",
        "    generator = generator.to(device)\n",
        "    generator.eval()\n",
        "\n",
        "\n",
        "    z_init = torch.randn((n_samples,generator.in_features)).to(device)\n",
        "    z_final = torch.randn((n_samples,generator.in_features)).to(device)\n",
        "\n",
        "    interpolation_images = []\n",
        "    for interp in range(0,n_iterpolations):\n",
        "        interp_0_1 = float(interp) / (n_iterpolations-1)\n",
        "        z = z_init*interp_0_1 + z_final*(1-interp_0_1)\n",
        "        x_rec = generator.decoder(z.to(device))\n",
        "        image_grid = make_grid(x_rec.cpu(),nrow=8,padding=1)\n",
        "        image_grid = image_grid.permute(1,2,0).detach().numpy()\n",
        "\n",
        "        interpolation_images.append((image_grid*255.0).astype(np.uint8))\n",
        "    interpolation_images += interpolation_images[::-1]\n",
        "\n",
        "    imname = results_path+'/gan_interpolation_ck.gif'\n",
        "    imageio.mimsave(imname, interpolation_images, duration=10)\n",
        "\n",
        "    with open(imname,'rb') as f:\n",
        "        from IPython.display import Image, display\n",
        "        display(Image(data=f.read(), format='png',width=512,height=512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LM4BXgU6ZLl"
      },
      "outputs": [],
      "source": [
        "# GAN Train function. We have a generator and discriminator models and their respective optimizers.\n",
        "def train_GAN(gen, disc,  train_loader, optimizer_gen, optimizer_disc,\n",
        "              num_epochs=10, model_name='gan_ck.ckpt', device='cpu'):\n",
        "    gen = gen.to(device)\n",
        "    gen.train() # Set the generator in train mode\n",
        "    disc = disc.to(device)\n",
        "    disc.train() # Set the discriminator in train mode\n",
        "\n",
        "    total_step = len(train_loader)\n",
        "    disc_losses_list = []\n",
        "    gen_losses_list=[]\n",
        "\n",
        "    # Iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Iterate the dataset\n",
        "        disc_loss_avg = 0\n",
        "        gen_loss_avg = 0\n",
        "        nBatches_g = 0\n",
        "        nBatches_d = 0\n",
        "        update_generator = epoch%2\n",
        "\n",
        "        for i, (real_images) in enumerate(train_loader):\n",
        "            # Get batch of samples and labels\n",
        "            real_images = real_images.to(device)\n",
        "            n_images = real_images.shape[0]\n",
        "\n",
        "            # Forward pass\n",
        "            # Generate random images with the generator\n",
        "            fake_images = gen.sample(n_images,device=device)\n",
        "\n",
        "            # Use the discriminator to obtain the probabilties for real and generate imee\n",
        "            prob_real = disc(real_images)\n",
        "            prob_fake = disc(fake_images)\n",
        "\n",
        "            # Generator loss\n",
        "            gen_loss = -torch.log(prob_fake).mean()\n",
        "            # Discriminator loss\n",
        "            disc_loss = -0.5*(torch.log(prob_real) + torch.log(1-prob_fake)).mean()\n",
        "\n",
        "\n",
        "            # We are going to update the discriminator and generator parameters alternatively at each iteration\n",
        "\n",
        "            if(update_generator):\n",
        "              # Optimize generator\n",
        "              # Backward and optimize\n",
        "              optimizer_gen.zero_grad()\n",
        "              gen_loss.backward() # Necessary to not erase intermediate variables needed for computing disc_loss gradient\n",
        "              optimizer_gen.step()\n",
        "              if gen_loss < 0.5:\n",
        "                update_generator = False\n",
        "              gen_loss_avg += gen_loss.cpu().item()\n",
        "              nBatches_d+=1\n",
        "\n",
        "            else:\n",
        "              # Optimize discriminator\n",
        "              # Backward and optimize\n",
        "              optimizer_disc.zero_grad()\n",
        "              disc_loss.backward()\n",
        "              optimizer_disc.step()\n",
        "              if disc_loss < 0.5:\n",
        "                update_generator = True\n",
        "              disc_loss_avg += disc_loss.cpu().item()\n",
        "              nBatches_g+=1\n",
        "          \n",
        "        if nBatches_d == 0:\n",
        "            print(\"Discriminator was not updated in epoch\", epoch)\n",
        "            disc_losses_list.append(disc_losses_list[-1])\n",
        "        else:\n",
        "            disc_losses_list.append(disc_loss_avg / nBatches_d)\n",
        "        if nBatches_g == 0:\n",
        "            print(\"Generator was not updated in epoch\", epoch)\n",
        "            gen_losses_list.append(gen_losses_list[-1])\n",
        "        else:\n",
        "            gen_losses_list.append(gen_loss_avg / nBatches_g)\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "          torch.save(gen.state_dict(), results_path+ '/' + model_name)\n",
        "          print(\"-----------------------Generated images:-----------------------\\n\")\n",
        "          generate_gan(gen, n_samples=16, device=device)\n",
        "\n",
        "          print(\"-----------------------Interpolated images:-----------------------\\n\")\n",
        "          interpolate_gan(gen, n_samples = 16, n_iterpolations =50, device=device)\n",
        "        model_epoch = f'gan_ck_{epoch}.ckpt'\n",
        "        torch.save(gen.state_dict(), results_path+ '/' + model_name)\n",
        "        # Save model\n",
        "\n",
        "    torch.save(gen.state_dict(), results_path+ '/' + model_name)\n",
        "\n",
        "\n",
        "    return disc_losses_list, gen_losses_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ7TtMC86ZLm",
        "outputId": "70dfecbd-00c8-4b93-e371-71b10420b5ed"
      },
      "outputs": [],
      "source": [
        "# Define Geneartor and Discriminator networks\n",
        "gan_gen = Generator(32)\n",
        "gan_disc = Discriminator()\n",
        "\n",
        "#Initialize indepdent optimizer for both networks\n",
        "learning_rate = .0005\n",
        "optimizer_gen = torch.optim.Adam(gan_gen.parameters(),lr = learning_rate, weight_decay=1e-5)\n",
        "optimizer_disc = torch.optim.Adam(gan_disc.parameters(),lr = learning_rate, weight_decay=1e-5)\n",
        "\n",
        "# Train the GAN\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "disc_loss_list,gen_loss_list = train_GAN(gan_gen,gan_disc, train_loader, optimizer_gen, optimizer_disc,\n",
        "                      num_epochs=20, model_name='gan_ck.ckpt', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-DC0eAK6ZLm",
        "outputId": "2f4c6930-ceee-4f0c-810d-626400307332"
      },
      "outputs": [],
      "source": [
        "#plot losses\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(disc_loss_list,label='Discriminator loss')\n",
        "plt.plot(gen_loss_list,label='Generator loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
